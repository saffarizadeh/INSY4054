{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Text Classification",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNbPvraRKCnHMbgKgIzL38d",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saffarizadeh/INSY4054/blob/main/Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNxXJclG9FuC"
      },
      "source": [
        "<img src=\"http://saffarizadeh.com/Logo.png\" width=\"300px\"/>\n",
        "\n",
        "# *INSY 4054: Emerging Technologies*\n",
        "\n",
        "# **Trained Models and Transfer Learning**\n",
        "\n",
        "Instructor: Dr. Kambiz Saffarizadeh\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCci0Rx4q2QD"
      },
      "source": [
        "Source: https://tfhub.dev/google/nnlm-en-dim50/2\n",
        "\n",
        "Read the complete tutorial: https://www.tensorflow.org/tutorials/keras/text_classification_with_hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azuPZUmoqvKW"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSOaanehBZd_"
      },
      "source": [
        "We first use `tensorflow_datasets` to load the imdb_reviews dataset.\n",
        "`tensorflow_datasets` loads large datasets in a specific way that works well with TensorFlow models. The data loaded using this method is not in numpy array format. Instead it is a TensorFlow Dataset (see https://www.tensorflow.org/api_docs/python/tf/data/Dataset)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVPj43sRqzoy"
      },
      "source": [
        "# Split the training set into 60% and 40%, so we'll end up with 15,000 examples\n",
        "# for training, 10,000 examples for validation and 25,000 examples for testing.\n",
        "train_data, validation_data, test_data = tfds.load(\n",
        "    name=\"imdb_reviews\", \n",
        "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
        "    as_supervised=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy8EHq2-AkB_"
      },
      "source": [
        "We load the pretrained model and extend it using a Sequential model to classify the input into two classes (positive vs. negative sentiment).\n",
        "Note that we set the model as `trainable` which means all parameters can be retrained. Since those parameters already have some weights and biases that work well, it is likely that the final weights and biases are close to what we already have in this part of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbZbOIpKrCk_"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim50/2\", input_shape=[], dtype=tf.string, trainable=True),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A75yXqrJOWq7",
        "outputId": "b28c0137-f8b0-4e36-a556-0580843bfa29"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 50)                48190600  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                816       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 48,191,433\n",
            "Trainable params: 48,191,433\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbrPk4QTrE5E"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItepYQcYDduX"
      },
      "source": [
        "Since the dataset we are using is large, we can choose the batch size we want to use to feed the data into our model. Before batching the data, we can shuffle it. To have the same shuffling outcome everytime we run this code on our machine, we can set a seed for the random shuffle. Here we use `10000`. We can use any number we want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mw-uTKJrGUo",
        "outputId": "e65a2bd5-50c9-430f-bc70-4272cbbd6b36"
      },
      "source": [
        "history = model.fit(train_data.shuffle(10000).batch(512),\n",
        "                    epochs=10,\n",
        "                    validation_data=validation_data.batch(512),\n",
        "                    verbose=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "30/30 [==============================] - 6s 94ms/step - loss: 0.7195 - accuracy: 0.4935 - val_loss: 0.6675 - val_accuracy: 0.6405\n",
            "Epoch 2/10\n",
            "30/30 [==============================] - 3s 84ms/step - loss: 0.6455 - accuracy: 0.6774 - val_loss: 0.5907 - val_accuracy: 0.7493\n",
            "Epoch 3/10\n",
            "30/30 [==============================] - 3s 84ms/step - loss: 0.5394 - accuracy: 0.7998 - val_loss: 0.4766 - val_accuracy: 0.8144\n",
            "Epoch 4/10\n",
            "30/30 [==============================] - 3s 85ms/step - loss: 0.3964 - accuracy: 0.8742 - val_loss: 0.3776 - val_accuracy: 0.8524\n",
            "Epoch 5/10\n",
            "30/30 [==============================] - 3s 84ms/step - loss: 0.2720 - accuracy: 0.9210 - val_loss: 0.3303 - val_accuracy: 0.8645\n",
            "Epoch 6/10\n",
            "30/30 [==============================] - 3s 83ms/step - loss: 0.1964 - accuracy: 0.9450 - val_loss: 0.3114 - val_accuracy: 0.8717\n",
            "Epoch 7/10\n",
            "30/30 [==============================] - 3s 85ms/step - loss: 0.1421 - accuracy: 0.9618 - val_loss: 0.3052 - val_accuracy: 0.8738\n",
            "Epoch 8/10\n",
            "30/30 [==============================] - 3s 83ms/step - loss: 0.1005 - accuracy: 0.9776 - val_loss: 0.3120 - val_accuracy: 0.8730\n",
            "Epoch 9/10\n",
            "30/30 [==============================] - 3s 82ms/step - loss: 0.0753 - accuracy: 0.9865 - val_loss: 0.3194 - val_accuracy: 0.8722\n",
            "Epoch 10/10\n",
            "30/30 [==============================] - 3s 82ms/step - loss: 0.0503 - accuracy: 0.9937 - val_loss: 0.3308 - val_accuracy: 0.8709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIXqDy1krIUt",
        "outputId": "88618c63-10f6-4154-f6a3-acc79db00a66"
      },
      "source": [
        "model.evaluate(test_data.batch(512), verbose=2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49/49 - 2s - loss: 0.3598 - accuracy: 0.8558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3597661852836609, 0.8557599782943726]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecMAnJ8yrLPx"
      },
      "source": [
        "new_reviews = [\"This was a great movie\", \"This was a very bad movie\"]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9J_UFuzraB9"
      },
      "source": [
        "new_reviews_array = np.array(new_reviews)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSiYetWjrceM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc2e3061-cdff-492c-fea7-a1ac9e1e8d3d"
      },
      "source": [
        "model(new_reviews_array)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
              "array([[0.98168576],\n",
              "       [0.14568348]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGpGvJkots3r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}