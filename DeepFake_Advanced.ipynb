{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saffarizadeh/INSY4054/blob/main/DeepFake_Advanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzcDdsWh9xXM"
      },
      "source": [
        "<img src=\"http://saffarizadeh.com/Logo.png\" width=\"300px\"/>\n",
        "\n",
        "# *INSY 4054: Emerging Technologies*\n",
        "\n",
        "# **Trained Models and Transfer Learning**\n",
        "## **DeepFake - Advanced**\n",
        "\n",
        "Instructor: Dr. Kambiz Saffarizadeh\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdO_RxQZLahB"
      },
      "source": [
        "# Improved Demo for paper \"First Order Motion Model for Image Animation\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio-ffmpeg"
      ],
      "metadata": {
        "id": "3kWB8o09k_tE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"pyyaml==5.3\""
      ],
      "metadata": {
        "id": "14UcOnP5lAD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCu4TJO6UVLY"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import imageio\n",
        "import cv2\n",
        "from IPython.display import HTML\n",
        "from skimage.transform import resize\n",
        "import matplotlib.animation as animation\n",
        "from google.colab import files\n",
        "import requests\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVQvGsoQ5Cvt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb40e459-4bd6-4f34-f6c3-20b7f70de801"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTUAa666_zsj"
      },
      "source": [
        "# Loading a Photo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ehKq7CmwnYv"
      },
      "source": [
        "#@title Choose an image { display-mode: \"form\" }\n",
        "\n",
        "image_url = \"https://www.saffarizadeh.com/ET/DF/statue-01.png\" #@param @param [\"https://www.saffarizadeh.com/ET/DF/statue-01.png\", \"https://www.saffarizadeh.com/ET/DF/statue-02.png\", \"https://www.saffarizadeh.com/ET/DF/statue-03.png\", \"https://www.saffarizadeh.com/ET/DF/statue-04.png\"]\n",
        "source_image = imageio.imread(image_url)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDllcUS7GFrp"
      },
      "source": [
        "If you prefer to upload your own photo run the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW2r4yqKGK3L"
      },
      "source": [
        "uploaded_image = files.upload()\n",
        "source_image = imageio.imread(list(uploaded_image.keys())[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ8w9T2Tz9Vq"
      },
      "source": [
        "plt.imshow(source_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HQXqtkY5vtR"
      },
      "source": [
        "Download and resize the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvINYFwH9ax9"
      },
      "source": [
        "source_image.shape # PNG pictures have 4 channels. The forth channel keeps a value for transparency"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDSz3G9t50Me"
      },
      "source": [
        "To properly crop the image around the face we first need to find the face. After finding the coordinates of the face, we can crop the image to become a square image centered around the face."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_7427iaZrp_"
      },
      "source": [
        "def crop_face_coordinates(image):\n",
        "  # Detect the face in image\n",
        "  gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
        "  face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "  faces = face_cascade.detectMultiScale(gray_image, 1.5, 1)\n",
        "  # Get the coordinates of the face (the first face in the image)\n",
        "  x, y, w, h = list(faces[0])\n",
        "  return (y, y+h, x, x+w)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Niyvur9V_SNK"
      },
      "source": [
        "If the image is not already properly cropped, run the following code to use this function and crop the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QoEcSU7E7pX"
      },
      "source": [
        "# If the image is not already properly cropped, uncomment and run the following code to use this function and crop the image.\n",
        "# (y1, y2, x1, x2) = crop_face_coordinates(source_image)\n",
        "# source_image = source_image[y1:y2, x1:x2]\n",
        "\n",
        "source_image = resize(source_image, (256, 256))[..., :3] # Here by using \":3\" we are getting rid of the 4th channel of the image (if the image is a PNG)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZOMhyQL_jIw"
      },
      "source": [
        "plt.imshow(source_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW-ipQXPOWUo"
      },
      "source": [
        "# Load Driving Video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtY8npJvwZI-"
      },
      "source": [
        "uploaded_video = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCT4YZko5U9C"
      },
      "source": [
        "video_file_name = list(uploaded_video.keys())[0]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOzdjIX46Pfd"
      },
      "source": [
        "We can use the `get_reader` method of `imageio` to load the video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY4tVIQiZXWe"
      },
      "source": [
        "reader = imageio.get_reader(video_file_name)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWfkP4kX6Zwl"
      },
      "source": [
        "We can also get the number of frames per second to be used later when we want to save the video."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMlpWMER193Z"
      },
      "source": [
        "fps = reader.get_meta_data()['fps']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqJIsETD6l0K"
      },
      "source": [
        "We loop through the reader and create a list of frames."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELPEVHXDZM5e"
      },
      "source": [
        "driving_video = [frame for frame in reader]\n",
        "reader.close()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoVDOTi06-Jn"
      },
      "source": [
        "We use the first frame of the video as the basis for face detection. We use the coordinates of the face from the first frame to crop the whole video. We also resize the video to 256 by 256."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC4WO-tXZM3I"
      },
      "source": [
        "# if we want to crop the whole video based on the first frame of the video:\n",
        "(y1, y2, x1, x2) = crop_face_coordinates(driving_video[0])\n",
        "\n",
        "cropped_video = []\n",
        "for i, frame in enumerate(driving_video):\n",
        "  # if we want to crop the video based on the position of face on each frame:\n",
        "  #(y1, y2, x1, x2) = crop_face_coordinates(driving_video[i])\n",
        "  cropped = frame[y1:y2, x1:x2]\n",
        "  cropped_video.append(resize(cropped, (256, 256))[..., :3])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCDNKsEGLtR6"
      },
      "source": [
        "# Download the DeepFake Repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCMFMJV7K-ag"
      },
      "source": [
        "!git clone https://github.com/AliaksandrSiarohin/first-order-model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBp6l_4bBYUL"
      },
      "source": [
        "cd first-order-model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjM7ubVfWrwT"
      },
      "source": [
        "# Create a Model and Load Checkpoints from the Downloaded Repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-d_eX70ZFWn"
      },
      "source": [
        "!gdown --id 1P27UddNfwV_NNbQqB40RkCPDaYnb9jwc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FQiXqQPWt5B"
      },
      "source": [
        "from demo import load_checkpoints\n",
        "generator, kp_detector = load_checkpoints(config_path='config/vox-256.yaml', checkpoint_path='deep_animator_model.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdFdasHEj3t7"
      },
      "source": [
        "# Perform Image Animation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r4pQY29HeYR"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB12II11kF4c"
      },
      "source": [
        "from demo import make_animation\n",
        "from skimage import img_as_ubyte\n",
        "\n",
        "predictions = make_animation(source_image, cropped_video, generator, kp_detector, relative=True)\n",
        "\n",
        "#save resulting video\n",
        "imageio.mimsave('generated.mp4', [img_as_ubyte(frame) for frame in predictions], fps=fps)\n",
        "#video can be downloaded from /content folder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY74WVfk7zQL"
      },
      "source": [
        "To show the video here on the Notebook, we use the following function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpkVsFpTlIXv"
      },
      "source": [
        "def display(source, driving, generated=None):\n",
        "    fig = plt.figure(figsize=(8 + 4 * (generated is not None), 6))\n",
        "\n",
        "    ims = []\n",
        "    for i in range(len(driving)):\n",
        "        cols = [source]\n",
        "        cols.append(driving[i])\n",
        "        if generated is not None:\n",
        "            cols.append(generated[i])\n",
        "        im = plt.imshow(np.concatenate(cols, axis=1), animated=True)\n",
        "        plt.axis('off')\n",
        "        ims.append([im])\n",
        "\n",
        "    ani = animation.ArtistAnimation(fig, ims, interval=fps, repeat_delay=1000)\n",
        "    plt.close()\n",
        "    return ani"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtuTLrbD3zvO"
      },
      "source": [
        "HTML(display(source_image, cropped_video, predictions).to_html5_video())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiRA4BAA-cot"
      },
      "source": [
        "# Add the Audio Back to the Animation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SjtkJBm_P9L"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SMWe4aQ_jvu"
      },
      "source": [
        "!rm audio.mp3 && rm generated_with_audio.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kolk7I_m821v"
      },
      "source": [
        "import subprocess\n",
        "_ = subprocess.call(f'ffmpeg -i {video_file_name} -f mp3 audio.mp3', shell=True)\n",
        "_ = subprocess.call('ffmpeg -i generated.mp4 -i audio.mp3 -strict -2 -f mp4 generated_with_audio.mp4', shell=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz-EgsOS9c_z"
      },
      "source": [
        "from base64 import b64encode\n",
        "mp4 = open('generated_with_audio.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"<video width=400 controls><source src=\"%s\" type=\"video/mp4\"></video>\"\"\" % data_url)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}