{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Automation Make Up Project - Student Version",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP2asg4Ayk+weG02R+20oy7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saffarizadeh/INSY4054/blob/main/Automation_Make_Up_Project_Student_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-zS-N3YprMF"
      },
      "source": [
        "<img src=\"http://saffarizadeh.com/Logo.png\" width=\"300px\"/>\n",
        "\n",
        "# *INSY 4054: Emerging Technologies*\n",
        "\n",
        "# **Automation Make Up Project**\n",
        "\n",
        "Instructor: Dr. Kambiz Saffarizadeh\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_OJ05fooC39"
      },
      "source": [
        "## Please read carefully\n",
        "\n",
        "In this project, we want to learn how to automate the process of analyzing separate paragraphs of news on a specific webpage.\n",
        "\n",
        "The target webpage is https://stories.marquette.edu/staying-curious-w-kate-harrison-74f97431079f.\n",
        "\n",
        "Please open and view the webpage.\n",
        "\n",
        "In next steps, after importing all needed libraries, we first download the webpage. Then using BeautifulSoup, we extract long paragraphs from the webpage. We then create a table to keep these data. Next, we pass the paragraphs to a sentiment analysis model and store the sentiments in a new column in the table. Finally, we create a few reports based on the sentiment analysis and store all tables in an Excel file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DebydpkhivsD"
      },
      "source": [
        "## Insert all needed libraries here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyYaQUQ7taDc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly-_r2gyi1DX"
      },
      "source": [
        "## Crawl the website\n",
        "\n",
        "Use the `get` method to download the following webpage:\n",
        "\n",
        "`https://stories.marquette.edu/staying-curious-w-kate-harrison-74f97431079f`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnnMdWVEtbEX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2uOYqNXi956"
      },
      "source": [
        "## Make a soup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCc1fTeRqMZ0"
      },
      "source": [
        "Use Beautiful Soup to create/make an HTML soup!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3gXGbqdtcef"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayFk114YjENT"
      },
      "source": [
        "## Using the soup, extract long paragraphs\n",
        "\n",
        "Find all paragraphs in the page (tag for paragraph is `p`).\n",
        "Add all paragraphs with more than 200 characters to a new list named `list1`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnA0TXGKjtmu"
      },
      "source": [
        "Titles: Store all review titles in a list named `list1`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i_iwsjWtdxR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gCpuLhTkIiw"
      },
      "source": [
        "## Create a `pandas` data frame and store `list1`\n",
        "\n",
        "Hint: you can first create a dictionary with `paragraph` as key and list1 as value. Then you can create a data frame from this dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LdLqxBKtk2a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlzHBSWtlHFh"
      },
      "source": [
        "Show the data frame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsf0fEsGpvKZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "OEjQ5Xms_fpI"
      },
      "source": [
        "#@title Run this cell to train a sentiment analysis model. This model directly comes from Activity 4 in Week 5-1 slides. Running this cell takes 1-2 minutes.\n",
        "%%capture\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "train_data, validation_data, test_data = tfds.load(name=\"imdb_reviews\", split=('train[:60%]', 'train[60%:]', 'test'), as_supervised=True)\n",
        "model = tf.keras.models.Sequential([\n",
        "    hub.KerasLayer(\"https://tfhub.dev/google/nnlm-en-dim50/2\", input_shape=[], dtype=tf.string, trainable=True),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "model.fit(train_data.shuffle(1).batch(512), epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np6e9fbCxZWe"
      },
      "source": [
        "The sentiment analysis model we use is trained on movie reviews. So, it might not be the best fit for the specific context of our automation. But first let's use the model and then judge the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0BN_VuHl1NC"
      },
      "source": [
        "After running the previous cell, pass the column containing the paragraphs to the model. To do so, run the following code after replacing `column_placeholder` with the actual column from the data frame:\n",
        "\n",
        "`sentiment = model(column_placeholder).numpy()`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlrntMp-tqvT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ-puD7tmoVL"
      },
      "source": [
        "Store `sentiment` as a new column in the data frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQFmK1NUtsZ_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlDHxRqumvrA"
      },
      "source": [
        "Show the data frame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBD3u8jJtviD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlG8L2HvmxzH"
      },
      "source": [
        "Select the rows with sentiment values above average."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgCYZa2ctwA_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arF5iPe4m6sD"
      },
      "source": [
        "Select the rows with sentiment values below average."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMxH6PG2txVM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etvp9ZqwnAgO"
      },
      "source": [
        "Create an Excel file with three sheets showing: 1) the main data frame, 2) the rows with sentiment values above average, and 3) the rows with sentiment values below average."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEWpKSlg8FQM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}